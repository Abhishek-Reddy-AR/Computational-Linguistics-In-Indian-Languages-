{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92eb6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required modules\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2b727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ad084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert input data into features as 'tokens' and their 'ner-tags'\n",
    "#it returns a dictionary containing training,validation and test splits of input data\n",
    "\n",
    "#if you want  features from scratch,then please pass preprocessed as False\n",
    "def load_data(train_from_scratch=False):\n",
    "    \n",
    "    #if preprocessed is true,then simply loading the already transformed dataset\n",
    "    if not train_from_scratch:\n",
    "        dataset= pickle.load(open('processed_dataset', \"rb\"))\n",
    "    \n",
    "    #else ,making dataset from scratch\n",
    "    else:\n",
    "        #loading the contents of input files\n",
    "        l=[]\n",
    "        with File.as_handle('hi_train.conll', 'r',encoding=\"utf8\") as fp:\n",
    "             l.append(fp.readlines())\n",
    "        \n",
    "        #to store tokens in a sentance and their ner tags\n",
    "        sent=[]\n",
    "        curr1=[]\n",
    "        curr2=[]\n",
    "        for i in range(len(l[0])):\n",
    "            s=l[0][i].split()\n",
    "            if len(s)>0 and s[0]!='#':\n",
    "                curr1.append(s[0])\n",
    "                curr2.append(s[-1])\n",
    "            else:\n",
    "                if len(curr1)>0:\n",
    "                    sent.append([curr1,curr2])\n",
    "                    curr1=[]\n",
    "                    curr2=[]\n",
    "        #making a label map \n",
    "        labels = ['B-CORP','B-CW','B-GRP','B-LOC','B-PER','B-PROD','I-CORP','I-CW','I-GRP','I-LOC','I-PER','I-PROD','O']\n",
    "        label_map = {label:i for i, label in enumerate(labels)}\n",
    "        \n",
    "        #converting labelsi.e ner tags into integer values\n",
    "        for i in range(len(sent)):\n",
    "            k=sent[i][1]\n",
    "            f=[]\n",
    "            for j in k:\n",
    "                f.append(label_map[j])\n",
    "            sent[i][1]=f\n",
    "        #makaing test,train and validation splits\n",
    "        \n",
    "        train_end=int(0.8*len(sent))\n",
    "        train=sent[:train_end]\n",
    "        validation=sent[train_end:]\n",
    "        \n",
    "        l=[]\n",
    "        #loading test data\n",
    "        with File.as_handle('hi_dev.conll', 'r',encoding=\"utf8\") as fp:\n",
    "             l.append(fp.readlines())\n",
    "        \n",
    "        #to store tokens in a sentance and their ner tags of test data\n",
    "        sent=[]\n",
    "        curr1=[]\n",
    "        curr2=[]\n",
    "        for i in range(len(l[0])):\n",
    "            s=l[0][i].split()\n",
    "            if len(s)>0 and s[0]!='#':\n",
    "                curr1.append(s[0])\n",
    "                curr2.append(s[-1])\n",
    "            else:\n",
    "                if len(curr1)>0:\n",
    "                    sent.append([curr1,curr2])\n",
    "                    curr1=[]\n",
    "                    curr2=[]\n",
    "        for i in range(len(sent)):\n",
    "            k=sent[i][1]\n",
    "            f=[]\n",
    "            for j in k:\n",
    "                f.append(label_map[j])\n",
    "            sent[i][1]=f\n",
    "        test=sent\n",
    "        #converting to dataframes\n",
    "        test = pd.DataFrame(test)\n",
    "        train=pd.DataFrame(train)\n",
    "        validation=pd.DataFrame(validation)\n",
    "        #renaming columns\n",
    "        test.columns=train.columns=validation.columns=[\"tokens\", \"ner_tags\"]\n",
    "        #storing them in a dictionary\n",
    "        dataset={'train':train,'test':test,'validation':validation}\n",
    "        #storing the dataset in pickle file\n",
    "        ds_file= open('processed_dataset', \"wb\")\n",
    "        pickle.dump(dataset,ds_file)\n",
    "        ds_file.close()\n",
    "    #returning dict dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a238d111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb49524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing req modules\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig ,AutoModelForTokenClassification,AdamW,get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from typing import Optional, List, Any,Union\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
    "from dataclasses import dataclass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ada794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for setting seed\n",
    "def set_seed(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748afdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for inputfeatures to the indic-bert model\n",
    "\n",
    "@dataclass\n",
    "class InputFeatures:\n",
    "    input_ids: Any\n",
    "    attention_mask: Any\n",
    "    token_type_ids: Any = None\n",
    "    label: Any = None\n",
    "    candidates: Any = None\n",
    "    example_id: str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c048c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create trainer \n",
    "def create_trainer(model,gradient_accumulation_steps,num_train_epochs,max_grad_norm):\n",
    "    #setting seed\n",
    "    set_seed(2)\n",
    "    \n",
    "    #initialing parameters for the trainer\n",
    "    train_params = dict(\n",
    "        accumulate_grad_batches=gradient_accumulation_steps,\n",
    "        #give accelerator as 'gpu' if you have gpus avalilable\n",
    "        accelerator=\"cpu\",\n",
    "        max_epochs=num_train_epochs,\n",
    "        gradient_clip_val=max_grad_norm,\n",
    "        enable_checkpointing =True\n",
    "    )\n",
    "    \n",
    "    #creating the trainer using pytorch\n",
    "    trainer = pl.Trainer(**train_params)\n",
    "    #returning trainer\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfad02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2399219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining named entity recognition class\n",
    "class ner(pl.LightningModule):\n",
    "    #if you want to train from scratch,please assign train_from_scatch value as true while initializing a variable of this class\n",
    "    def __init__(self,train_from_scratch=False):\n",
    "        #calling base modules init\n",
    "        super().__init__()\n",
    "        \n",
    "        #initializing parameters\n",
    "        self.scratch=train_from_scratch\n",
    "        self.max_seq_length=128\n",
    "        self.train_batch_size=64\n",
    "        self.gradient_accumulation_steps=1\n",
    "        self.num_train_epochs=5\n",
    "        self.warmup_steps=0\n",
    "        self.eval_batch_size=64\n",
    "        self.weight_decay=0.0\n",
    "        self.learning_rate=2e-5\n",
    "        self.adam_epsilon=1e-8\n",
    "        self.max_grad_norm=1.0\n",
    "        self.pad_token_label_id = CrossEntropyLoss().ignore_index\n",
    "        #loading dataset\n",
    "        self.dataset=load_data(train_from_scratch=self.scratch)\n",
    "        self.labels =['B-CORP','B-CW','B-GRP','B-LOC','B-PER','B-PROD','I-CORP','I-CW','I-GRP','I-LOC','I-PER','I-PROD','O']\n",
    "        args = {'num_labels':13}\n",
    "        \n",
    "        \n",
    "        #getting the inidc bert model and its tokenizer\n",
    "        #by passing num_labels=7 the model we will get will have a softmax with 13 diff output classes as the final layer\n",
    "        self.config= AutoConfig.from_pretrained('ai4bharat/indic-bert',**args)\n",
    "        self.tokenizer= AutoTokenizer.from_pretrained('ai4bharat/indic-bert',config=self.config)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert',config=self.config)\n",
    "        \n",
    "    #function for forward pass into the model\n",
    "    def forward(self, **inputs):\n",
    "        return self.model(**inputs)\n",
    "    \n",
    "    #function to load the features,i.e conversion of dataset features into InputFeatures format of the indic bert model\n",
    "    def load_features(self,mode):\n",
    "        #conversion to inputfeatures\n",
    "        features = self.convert_examples_to_features(mode)\n",
    "        return features\n",
    "    \n",
    "    #function to convert dataset features to inputfeatures format of the model\n",
    "    def convert_examples_to_features(self,mode):\n",
    "        #to store the converted features\n",
    "        features=[]\n",
    "        #getting the current modes features\n",
    "        data=self.dataset[mode]\n",
    "        #renaming columns\n",
    "        data.columns=['sentence','word_labels']\n",
    "        #converting dataset feature i.e['sentence','word_labels'] into inputfeatures format i.e inputids,token_type_ids\n",
    "                                                                                                #attention_mask,encoded_labels\n",
    "        for index in range(len(data)):\n",
    "            #getting the current sentence and its word labels\n",
    "            sentence = data.sentence[index]  \n",
    "            labels = data.word_labels[index]\n",
    "            #appending the initial token of every sentance by the special token\n",
    "            input_ids=[2]\n",
    "            token_type_ids=[0]\n",
    "            attention_mask=[1]\n",
    "            encoded_labels =[-100]\n",
    "            \n",
    "            l=0\n",
    "            #next for each word in the sentance\n",
    "            for word in sentence:\n",
    "                #getting the encodings of the word,by passing it into the indic-bert tokenizer\n",
    "                encoding=self.tokenizer(word,add_special_tokens=False)\n",
    "                #if the len of inputt ids in the curr encoding is greater then max seq len -1 then skipping that word\n",
    "                le=len(encoding['input_ids'])\n",
    "                if len(input_ids)+le>=self.max_seq_length-1:\n",
    "                    break\n",
    "                #appeding the curr word encodings into the respective lists\n",
    "                input_ids.extend(encoding['input_ids'])\n",
    "                token_type_ids.extend(encoding['token_type_ids'])\n",
    "                attention_mask.extend(encoding['attention_mask'])\n",
    "                #assging only the first input id of the curr word to the ner tag of that word in the sentance \n",
    "                #and assigning the reaming input ids label values as -100\n",
    "                encoded_labels.append(labels[l]) \n",
    "                l+=1\n",
    "                for i in range(len(encoding['input_ids'])-1):\n",
    "                    encoded_labels.append(-100)\n",
    "            #adding a special token at the end of the sentance\n",
    "            input_ids.append(3)\n",
    "            token_type_ids.append(0)\n",
    "            attention_mask.append(1)\n",
    "            encoded_labels.append(-100)\n",
    "            #if the len of input ids in curr sentance id not 128 then appending dummy values\n",
    "            for extra in range(128-len(input_ids)):\n",
    "                input_ids.append(0)\n",
    "                token_type_ids.append(0)\n",
    "                attention_mask.append(0)\n",
    "                encoded_labels.append(-100)\n",
    "            if len(encoded_labels)>128:\n",
    "              continue\n",
    "            #converting the current sentance into the inputfeatures varible and appending to features list\n",
    "            features.append(InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=encoded_labels\n",
    "            ) )\n",
    "        #returning inputfeatures\n",
    "        return features\n",
    "    \n",
    "    #function to input features into batches and make them into DataLoader variable\n",
    "    def make_loader(self, features, batch_size):\n",
    "        #conversion to tensors\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "        all_token_type_ids = torch.tensor([f.token_type_ids or 0 for f in features], dtype=torch.long)\n",
    "        all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "        #splitting into batches\n",
    "        return DataLoader(\n",
    "            TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels),\n",
    "            batch_size=batch_size,)\n",
    "    \n",
    "    #function to preapare the train data to be given into the model\n",
    "    def train_dataloader(self):\n",
    "        #getting train batch size\n",
    "        train_batch_size = self.train_batch_size\n",
    "        #converting train data features into inputfeatures format\n",
    "        train_features = self.load_features('train')\n",
    "        #getting  dataloader on train features and train batch size\n",
    "        dataloader = self.make_loader(train_features, train_batch_size)\n",
    "        \n",
    "        #initializing a linear schedular\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) // (train_batch_size * 1))\n",
    "            // self.gradient_accumulation_steps\n",
    "            * float(self.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(self.opt, num_warmup_steps=self.warmup_steps, num_training_steps=t_total)\n",
    "        self.lr_scheduler = scheduler\n",
    "        \n",
    "        #returning train dataloader\n",
    "        return dataloader\n",
    "    \n",
    "    #function to preapare the validation data to be given into the model\n",
    "    def val_dataloader(self):\n",
    "        #converting validation data features into inputfeatures format\n",
    "        dev_features = self.load_features('validation')\n",
    "        #getting validation dataloader\n",
    "        dataloader = self.make_loader(dev_features, self.eval_batch_size)\n",
    "        return dataloader\n",
    "\n",
    "    #function to preapare the test data to be given into the model\n",
    "    def test_dataloader(self):\n",
    "        #converting test data features into inputfeatures format\n",
    "        test_features = self.load_features('test')\n",
    "        #getting test dataloader\n",
    "        dataloader = self.make_loader(test_features, self.eval_batch_size)\n",
    "        return dataloader\n",
    "    \n",
    "    #function to perform training step on a single batch of data\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #converting inputfeatures to dict\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1],'token_type_ids':batch[2], 'labels': batch[3]}\n",
    "        #getting the outputs from the model\n",
    "        outputs = self(**inputs)\n",
    "        #getting the loss from the current pass\n",
    "        loss = outputs[0]\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    #function to perform validation step on a single batch of data\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        #converting inputfeatures to dict\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1],'token_type_ids':batch[2], 'labels': batch[3]}\n",
    "        #getting the outputs from the model\n",
    "        outputs = self(**inputs)\n",
    "        #getting loss and softmax values\n",
    "        tmp_eval_loss, logits = outputs[:2]\n",
    "        preds = logits.detach().cpu().numpy()\n",
    "        #getting actual label ids\n",
    "        out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        #returning values as dict\n",
    "        return {'val_loss': tmp_eval_loss.detach().cpu(),'pred': preds,'target': out_label_ids}\n",
    "\n",
    "    #function to perform test step on a batch of data\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        return self.validation_step(batch, batch_nb)\n",
    "    \n",
    "    #function to configure optimizer\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        #getting the parameters to optimize from inidc-bert model\n",
    "        model = self.model\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in model.named_parameters()\n",
    "                           if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': self.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                'params': [p for n, p in model.named_parameters()\n",
    "                           if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0,\n",
    "            },\n",
    "        ]\n",
    "        #initializing the adam optimizer\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.learning_rate,\n",
    "                          eps=self.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        #returning the optimizer\n",
    "        return [optimizer]\n",
    "\n",
    "    #function to perform optimizatuon step\n",
    "    def optimizer_step(self, epoch=None, batch_idx=None, optimizer=None, optimizer_idx=None,optimizer_closure=None, \n",
    "                       on_tpu=None, using_native_amp=None, using_lbfgs=None):\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step()\n",
    "    \n",
    "    #function to calculate our required to f-score\n",
    "    def _eval_end(self, outputs):\n",
    "        #getting the predicted labels \n",
    "        preds = np.concatenate([x['pred'] for x in outputs], axis=0)\n",
    "        preds = np.argmax(preds, axis=2)\n",
    "        #gettinf actual labels\n",
    "        out_label_ids = np.concatenate([x['target'] for x in outputs], axis=0)\n",
    "        #getting label map\n",
    "        label_map = {i: label for i, label in enumerate(self.labels)}\n",
    "        #to store mapped values\n",
    "        out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "        preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "        \n",
    "        #mapping lables values from int to string\n",
    "        for i in range(out_label_ids.shape[0]):\n",
    "            for j in range(out_label_ids.shape[1]):\n",
    "                if out_label_ids[i, j] != self.pad_token_label_id:\n",
    "                    out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
    "                    preds_list[i].append(label_map[preds[i][j]])\n",
    "        #getting the f score on actual and predicted labels\n",
    "        macro_fscore=f1_score(out_label_list, preds_list)\n",
    "        micro_fscore=accuracy_score(out_label_list, preds_list)\n",
    "        #returning f score\n",
    "        return macro_fscore,micro_fscore\n",
    "    \n",
    "    #function to compute our req metric(f-score) on validation end i.e the outputs is actually the appending of outputs\n",
    "    #from diff validation batchs i.e appending of outputs from the validation step\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        #getting f score\n",
    "        f1,f2 = self._eval_end(outputs)\n",
    "    #function to compute our req metric(f-score) on test end\n",
    "    def test_epoch_end(self, outputs):\n",
    "        #getting fcore on test data\n",
    "        f1,f2 = self._eval_end(outputs)\n",
    "        #writing the fscore into the file\n",
    "        self.d.write('micro_fscore:'+str(f2))\n",
    "        self.d.write('macro_fscore:'+str(f1))\n",
    "    #function to start the running of whole ner model\n",
    "    def run_module(self):\n",
    "        #creating trainer\n",
    "        trainer = create_trainer(self, self.gradient_accumulation_steps,self.num_train_epochs,self.max_grad_norm)\n",
    "        #congiguring optimizer\n",
    "        opt=self.configure_optimizers()\n",
    "        #opening file to write f scores\n",
    "        self.d=open('f_score','w')\n",
    "        \n",
    "        #if train from scratch is true\n",
    "        if self.scratch:\n",
    "            #getting train ,test and validation dataloaders\n",
    "            td=self.train_dataloader()\n",
    "            vd=self.val_dataloader()\n",
    "            te=self.test_dataloader()\n",
    "            #training the model on train dataloader\n",
    "            trainer.fit(self,train_dataloaders=td,val_dataloaders=vd)\n",
    "            #storing to tuned model\n",
    "            trainer.save_checkpoint(\"tuned.ckpt\")\n",
    "            #computing training f score and writing into file\n",
    "            self.d.write('training f-score:')\n",
    "            trainer.test(self,dataloaders=td)\n",
    "            #computing validation f score and writing into file\n",
    "            self.d.write('\\n')\n",
    "            self.d.write('validation f-score:')\n",
    "            trainer.test(self,dataloaders=vd)\n",
    "            #computing test f score and writing into file\n",
    "            self.d.write('\\n')\n",
    "            self.d.write('test f-score:')\n",
    "            trainer.test(self,dataloaders=te)\n",
    "            #closing the file\n",
    "            self.d.close()\n",
    "            \n",
    "        else:\n",
    "            #getting train ,test and validation dataloaders\n",
    "            td=self.train_dataloader()\n",
    "            vd=self.val_dataloader()\n",
    "            te=self.test_dataloader()\n",
    "            \n",
    "            #loading from the already tuned model\n",
    "            checkpoints='tuned.ckpt'\n",
    "            trainer.fit(self,train_dataloaders=td,val_dataloaders=vd,ckpt_path=checkpoints)\n",
    "            #computing training f score and writing into file\n",
    "            self.d.write('training f-score:')\n",
    "            trainer.test(self,dataloaders=td)\n",
    "            #computing validation f score and writing into file\n",
    "            self.d.write('\\n')\n",
    "            self.d.write('validation f-score:')\n",
    "            trainer.test(self,dataloaders=vd)\n",
    "            #computing test f score and writing into file\n",
    "            self.d.write('\\n')\n",
    "            self.d.write('test f-score:')\n",
    "            trainer.test(self,dataloaders=te)\n",
    "            #closing the file\n",
    "            self.d.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9782ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155b2fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForTokenClassification: ['predictions.bias', 'predictions.LayerNorm.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.dense.bias', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "var=ner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1b6de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Restoring states from the checkpoint path at tuned.ckpt\n",
      "Restored all states from the checkpoint file at tuned.ckpt\n",
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | AlbertForTokenClassification | 32.9 M\n",
      "-------------------------------------------------------\n",
      "32.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "32.9 M    Total params\n",
      "131.452   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d90d3b3547a41909db6e29cf030a2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb8c74b659c422fa69e011dff38d2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a413bafb9e482aa622e317b8336186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "var.run_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7c038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e02c187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421509c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
