{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a152b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required modules\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "# Creating a variable for Class WhitespaceTokenizer\n",
    "tk = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ec6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the file\n",
    "#only reading some part of the file , due to hardware constraints\n",
    "with open('hi.txt',encoding=\"utf8\") as f:\n",
    "    l=[]\n",
    "    for i in range(50000):\n",
    "        l.append(f.readline()[:-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37888383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations\n",
    "l_new=[]\n",
    "for line in l:\n",
    "     # + means match one or more\n",
    "    regex_sub = re.sub(r\"[,.;@#?!&$]+\", ' ', line) \n",
    "    l_new.append(regex_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83175c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting lines using whitespace tokenizer\n",
    "words_list1=[]\n",
    "for sent in l_new:\n",
    "    words_list1.append(tk.tokenize(sent))\n",
    "#removing non hindi words\n",
    "words_list=[]\n",
    "for sent in words_list1:\n",
    "    curr=[]\n",
    "    for word in sent:\n",
    "        if  not(word.isascii() or word.isdigit() or word.isdecimal()):\n",
    "            curr.append(word)\n",
    "    words_list.append(curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb64f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNICODE values of hindi characters\n",
    "hindi_unicodes=[b'\\\\u0900',b'\\\\u0901',b'\\\\u0902',b'\\\\u0903',b'\\\\u0904',b'\\\\u0905',b'\\\\u0906',b'\\\\u0907',\n",
    "                b'\\\\u0908',b'\\\\u0909',b'\\\\u090a',b'\\\\u090b',b'\\\\u090c',b'\\\\u090d',b'\\\\u090e',b'\\\\u090f',\n",
    "                \n",
    "                b'\\\\u0910',b'\\\\u0911',b'\\\\u0912',b'\\\\u0913',b'\\\\u0914',b'\\\\u0915',b'\\\\u0916',b'\\\\u0917',\n",
    "                b'\\\\u0918',b'\\\\u0919',b'\\\\u091a',b'\\\\u091b',b'\\\\u091c',b'\\\\u091d',b'\\\\u091e',b'\\\\u091f',\n",
    "               \n",
    "                b'\\\\u0920',b'\\\\u0921',b'\\\\u0922',b'\\\\u0923',b'\\\\u0924',b'\\\\u0925',b'\\\\u0926',b'\\\\u0927',\n",
    "                b'\\\\u0928',b'\\\\u0929',b'\\\\u092a',b'\\\\u092b',b'\\\\u092c',b'\\\\u092d',b'\\\\u092e',b'\\\\u092f',\n",
    "               \n",
    "                b'\\\\u0930',b'\\\\u0931',b'\\\\u0932',b'\\\\u0933',b'\\\\u0934',b'\\\\u0935',b'\\\\u0936',b'\\\\u0937',\n",
    "                b'\\\\u0938',b'\\\\u0939',b'\\\\u093a',b'\\\\u093b',b'\\\\u093c',b'\\\\u093d',b'\\\\u093e',b'\\\\u093f',\n",
    "               \n",
    "                b'\\\\u0940',b'\\\\u0941',b'\\\\u0942',b'\\\\u0943',b'\\\\u0944',b'\\\\u0945',b'\\\\u0946',b'\\\\u0947',\n",
    "                b'\\\\u0948',b'\\\\u0949',b'\\\\u094a',b'\\\\u094b',b'\\\\u094c',b'\\\\u094d',b'\\\\u094e',b'\\\\u094f',\n",
    "                \n",
    "                b'\\\\u0950',b'\\\\u0951',b'\\\\u0952',b'\\\\u0953',b'\\\\u0954',b'\\\\u0955',b'\\\\u0956',b'\\\\u0957',\n",
    "                b'\\\\u0958',b'\\\\u0959',b'\\\\u095a',b'\\\\u095b',b'\\\\u095c',b'\\\\u095d',b'\\\\u095e',b'\\\\u095f',\n",
    "                \n",
    "                b'\\\\u0960',b'\\\\u0961',b'\\\\u0962',b'\\\\u0963',b'\\\\u0964',b'\\\\u0965',b'\\\\u0966',b'\\\\u0967',\n",
    "                b'\\\\u0968',b'\\\\u0969',b'\\\\u096a',b'\\\\u096b',b'\\\\u096c',b'\\\\u096d',b'\\\\u096e',b'\\\\u096f',\n",
    "               \n",
    "                b'\\\\u0970',b'\\\\u0971',b'\\\\u0972',b'\\\\u0973',b'\\\\u0974',b'\\\\u0975',b'\\\\u0976',b'\\\\u0977',\n",
    "                b'\\\\u0978',b'\\\\u0979',b'\\\\u097a',b'\\\\u097b',b'\\\\u097c',b'\\\\u097d',b'\\\\u097e',b'\\\\u097f'\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f597e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unicode values of standalone vowels in hindi\n",
    "standalone_vowels=[b'\\\\u0904',b'\\\\u0905',b'\\\\u0906',b'\\\\u0907',b'\\\\u0908',b'\\\\u0909',b'\\\\u090a',b'\\\\u090b',\n",
    "                  b'\\\\u090c',b'\\\\u090d',b'\\\\u090e',b'\\\\u090f',b'\\\\u0910',b'\\\\u0911',b'\\\\u0912',b'\\\\u0913',\n",
    "                  b'\\\\u0914']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f776580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unicode values of matras in hindi\n",
    "matras=[b'\\\\u0900',b'\\\\u0901',b'\\\\u0902',b'\\\\u0903',b'\\\\u093a',b'\\\\u093b',b'\\\\u093c',b'\\\\u093e',b'\\\\u093f',\n",
    "              b'\\\\u0940',b'\\\\u0941',b'\\\\u0942',b'\\\\u0943',b'\\\\u0944',b'\\\\u0945',b'\\\\u0946',b'\\\\u0947',b'\\\\u0948',\n",
    "              b'\\\\u0949',b'\\\\u094a',b'\\\\u094b',b'\\\\u094c',b'\\\\u094d',b'\\\\u094e',b'\\\\u094f',b'\\\\u0950',b'\\\\u0951',\n",
    "              b'\\\\u0952',b'\\\\u0953',b'\\\\u0954',b'\\\\u0955',b'\\\\u0956',b'\\\\u0957',b'\\\\u0962',b'\\\\u0963']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d6d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unicode values of consonantss in hindi\n",
    "consonants=[b'\\\\u0915',b'\\\\u0916',b'\\\\u0917',b'\\\\u0918',b'\\\\u0919',b'\\\\u091a',b'\\\\u091b',b'\\\\u091c',b'\\\\u091d',\n",
    "            b'\\\\u091e',b'\\\\u091f',b'\\\\u0920',b'\\\\u0921',b'\\\\u0922',b'\\\\u0923',b'\\\\u0924',b'\\\\u0925',b'\\\\u0926',\n",
    "            b'\\\\u0927',b'\\\\u0928',b'\\\\u0929',b'\\\\u092a',b'\\\\u092b',b'\\\\u092c',b'\\\\u092d',b'\\\\u092e',b'\\\\u092f',\n",
    "            b'\\\\u0930',b'\\\\u0931',b'\\\\u0932',b'\\\\u0933',b'\\\\u0934',b'\\\\u0935',b'\\\\u0936',b'\\\\u0937',b'\\\\u0938',\n",
    "            b'\\\\u0939',b'\\\\u0958',b'\\\\u0959',b'\\\\u095a',b'\\\\u095b',b'\\\\u095c',b'\\\\u095d',b'\\\\u095e',b'\\\\u095f',\n",
    "            b'\\\\u0960',b'\\\\u0961']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e195075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unicode values of digits in hindi\n",
    "digits=[b'\\\\u0966',b'\\\\u0967',b'\\\\u0968',b'\\\\u0969',b'\\\\u096a',b'\\\\u096b',b'\\\\u096c',b'\\\\u096d',b'\\\\u096e',b'\\\\u096f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d69bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unicode values of other chars in hindi\n",
    "symbols=[b'\\\\u093d',b'\\\\u0964',b'\\\\u0965',b'\\\\u0970',b'\\\\u0971',b'\\\\u0972',b'\\\\u0973',b'\\\\u0974',b'\\\\u0975',\n",
    "         b'\\\\u0976',b'\\\\u0977',b'\\\\u0978',b'\\\\u0979',b'\\\\u097a',b'\\\\u097b',b'\\\\u097c',b'\\\\u097d',b'\\\\u097e',\n",
    "         b'\\\\u097f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f93fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting only the hindi characters\n",
    "words=[]\n",
    "#for each sentance\n",
    "for sent in words_list:\n",
    "    #for each word\n",
    "    for word in sent:\n",
    "        l=[]\n",
    "        #for each character\n",
    "        for char in word:\n",
    "            #if the character belongs to hindi lang\n",
    "            e=char.encode(\"unicode_escape\")\n",
    "            if e in hindi_unicodes:\n",
    "                #adding it to list\n",
    "                l.append(char)\n",
    "        #storing the hindi words \n",
    "        words.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f16621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the unicode mistake of not encoding the halanta character\n",
    "corrected_words=[]\n",
    "#for each word\n",
    "for i in range(len(words)):\n",
    "    char=[]\n",
    "    #for each character\n",
    "    for j in range(len(words[i])):\n",
    "        c=words[i][j].encode(\"unicode_escape\")\n",
    "        #if the character is in vowels or matras or digits or other symbols then no need for any modification\n",
    "        if c in standalone_vowels or c in matras or c in digits or c in symbols:\n",
    "            char.append(words[i][j])\n",
    "        #else if the character is a consonant\n",
    "        else:\n",
    "            char.append(words[i][j])\n",
    "            #if this consonant is the end of the word and there is no mantra after that\n",
    "            if j==len(words[i])-1:\n",
    "                #then we add halanta after that\n",
    "                char.append('h')\n",
    "            #if the next character after the current consonant is not a matra \n",
    "            elif words[i][j+1].encode(\"unicode_escape\") not in matras:\n",
    "                #then we add halanta after that\n",
    "                char.append('h')\n",
    "    #adding the corrected word to list\n",
    "    corrected_words.append(char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ef6be",
   "metadata": {},
   "source": [
    "## 3.a:character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f3fbf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store the character unigrams and their count\n",
    "character_unigrams=dict()\n",
    "#for each word\n",
    "for i in range(len(corrected_words)):\n",
    "    #for each character\n",
    "    for j in range(len(corrected_words[i])):\n",
    "        curr=corrected_words[i][j]\n",
    "        #if the character is in dict\n",
    "        if curr in character_unigrams.keys():\n",
    "            #increment count\n",
    "            character_unigrams[curr]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count as 1\n",
    "            character_unigrams[curr]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd524c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting character unigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(character_unigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#storing both character unigrams and their counts in dict,for later use in q3.d\n",
    "char_zipf={k: v for k, v in sorted(character_unigrams.items(), key=lambda item: item[1],reverse=True)}\n",
    "#writing top 100 character unigrams into text file\n",
    "with io.open('character_unigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843c6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fca7434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store the character bigrams and their count \n",
    "character_bigrams=dict()\n",
    "#for each word\n",
    "for i in range(len(corrected_words)):\n",
    "    #for each bigram \n",
    "    for j in range(len(corrected_words[i])-1):\n",
    "        curr_tup=tuple([corrected_words[i][j],corrected_words[i][j+1]])\n",
    "        #if the current character bigram is in dict\n",
    "        if curr_tup in character_bigrams.keys():\n",
    "            #increament count\n",
    "            character_bigrams[curr_tup]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            character_bigrams[curr_tup]=1\n",
    "\n",
    "#sorting character bigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(character_bigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#writing top 100 character bigrams into text file\n",
    "with io.open('character_bigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i][0])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][1])\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e47342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store the character trigrams and their count \n",
    "character_trigrams=dict()\n",
    "#for each word\n",
    "for i in range(len(corrected_words)):\n",
    "    #for each trigram\n",
    "    for j in range(len(corrected_words[i])-2):\n",
    "        curr_tup=tuple([corrected_words[i][j],corrected_words[i][j+1],corrected_words[i][j+2]])\n",
    "        #if the current character trigram is in dict\n",
    "        if curr_tup in character_trigrams.keys():\n",
    "            #increament count\n",
    "            character_trigrams[curr_tup]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            character_trigrams[curr_tup]=1\n",
    "\n",
    "#sorting character trigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(character_trigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#writing top 100 character trigrams into text file\n",
    "with io.open('character_trigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i][0])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][1])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][2])        \n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6094b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store the character quadrigrams and their count \n",
    "character_quadrigrams=dict()\n",
    "#for each word\n",
    "for i in range(len(corrected_words)):\n",
    "    #for each quadrigram\n",
    "    for j in range(len(corrected_words[i])-3):\n",
    "        curr_tup=tuple([corrected_words[i][j],corrected_words[i][j+1],corrected_words[i][j+2],corrected_words[i][j+3]])\n",
    "        #if the current character quadrigram is in dict\n",
    "        if curr_tup in character_quadrigrams.keys():\n",
    "            #increament count\n",
    "            character_quadrigrams[curr_tup]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            character_quadrigrams[curr_tup]=1\n",
    "\n",
    "#sorting character quadrigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(character_quadrigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#writing top 100 character quadrigrams into text file\n",
    "with io.open('character_quadrigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i][0])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][1])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][2]) \n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][3]) \n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893e521",
   "metadata": {},
   "source": [
    "## 3.b:word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a7c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store word unigrams and their counts\n",
    "word_unigrams=dict()\n",
    "#for each sentance\n",
    "for i in range(len(words_list)):\n",
    "    #for each word unigram\n",
    "    for j in range(len(words_list[i])):\n",
    "        curr=words_list[i][j]\n",
    "        #if the curr unigram is in dict\n",
    "        if curr in word_unigrams.keys():\n",
    "            #increament count\n",
    "            word_unigrams[curr]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            word_unigrams[curr]=1\n",
    "\n",
    "#sorting word unigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(word_unigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#storing both word unigrams and their counts in dict,for later use in q3.d\n",
    "word_zipf={k: v for k, v in sorted(word_unigrams.items(), key=lambda item: item[1],reverse=True)}\n",
    "#writing top 100 word unigrams into text file\n",
    "with io.open('word_unigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "032c63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store word bigrams and their counts\n",
    "word_bigrams=dict()\n",
    "#for each sentance\n",
    "for i in range(len(words_list)):\n",
    "    #for each word bigram\n",
    "    for j in range(len(words_list[i])-1):\n",
    "        curr_tup=tuple([words_list[i][j],words_list[i][j+1]])\n",
    "        #if the curr bigram is in dict\n",
    "        if curr_tup in word_bigrams.keys():\n",
    "            #increament count\n",
    "            word_bigrams[curr_tup]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            word_bigrams[curr_tup]=1\n",
    "#sorting word bigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(word_bigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#writing top 100 word bigrams into text file\n",
    "with io.open('word_bigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i][0])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][1])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d3e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store word trigrams and their counts\n",
    "word_trigrams=dict()\n",
    "#for each sentance\n",
    "for i in range(len(words_list)):\n",
    "    #for each word trigrams\n",
    "    for j in range(len(words_list[i])-2):\n",
    "        curr_tup=tuple([words_list[i][j],words_list[i][j+1],words_list[i][j+2]])\n",
    "        #if the curr word trigrams is in dict\n",
    "        if curr_tup in word_trigrams.keys():\n",
    "            #increament count\n",
    "            word_trigrams[curr_tup]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            word_trigrams[curr_tup]=1\n",
    "#sorting word trigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(word_trigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#writing top 100 word trigrams into text file\n",
    "with io.open('word_trigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i][0])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][1])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][2])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ead17bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store word quadrigrams and their counts\n",
    "word_quadrigrams=dict()\n",
    "#for each sentance\n",
    "for i in range(len(words_list)):\n",
    "    #for each word quadrigrams\n",
    "    for j in range(len(words_list[i])-3):\n",
    "        curr_tup=tuple([words_list[i][j],words_list[i][j+1],words_list[i][j+2],words_list[i][j+3]])\n",
    "        #if the curr word quadrigrams is in dict\n",
    "        if curr_tup in word_quadrigrams.keys():\n",
    "            #increament count\n",
    "            word_quadrigrams[curr_tup]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            word_quadrigrams[curr_tup]=1\n",
    "#sorting word quadrigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(word_quadrigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#writing top 100 word quadrigrams into text file\n",
    "with io.open('word_quadrigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i][0])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][1])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][2])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][3])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ba32e",
   "metadata": {},
   "source": [
    "## 3.c:syllable level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17d50b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return syllables from a given word\n",
    "def syllable(word):\n",
    "    #getting characters in current word\n",
    "    chars=[i for i in word]\n",
    "    #to store syllables\n",
    "    syllables=[]\n",
    "    #for each char\n",
    "    for i in range(len(chars)):\n",
    "        #if the char is not in mantras,then new syllable starts\n",
    "        if chars[i].encode(\"unicode_escape\") not in matras:\n",
    "            syllables.append(chars[i])\n",
    "        #if the char is in mantras\n",
    "        else:\n",
    "            try:\n",
    "                #then it is a part of the current syllable\n",
    "                syllables[-1]=syllables[-1]+chars[i]\n",
    "            except:\n",
    "                continue\n",
    "    #returning syllables\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad35dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store syllables of each word\n",
    "syllables_list=[]\n",
    "#for each sentance\n",
    "for sent in words_list:\n",
    "    #for each word\n",
    "    for word in sent:\n",
    "        #adding that words syllables to list\n",
    "        syllables_list.append(syllable(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3b50cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store syllable unigrams and their counts\n",
    "syllable_unigrams=dict()\n",
    "#for each word\n",
    "for i in range(len(syllables_list)):\n",
    "    #for each unigram syllable\n",
    "    for j in range(len(syllables_list[i])):\n",
    "        curr=syllables_list[i][j]\n",
    "        #if the curr syllable unigram is in dict\n",
    "        if curr in syllable_unigrams.keys():\n",
    "            #increament count\n",
    "            syllable_unigrams[curr]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            syllable_unigrams[curr]=1\n",
    "#sorting syllable unigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(syllable_unigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#storing both syllable unigrams and their counts in dict,for later use in q3.d\n",
    "syllable_zipf={k: v for k, v in sorted(syllable_unigrams.items(), key=lambda item: item[1],reverse=True)}\n",
    "#writing top 100 syllable unigrams into text file\n",
    "with io.open('syllable_unigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0695c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store syllable bigrams and their counts\n",
    "syllable_bigrams=dict()\n",
    "#for each word\n",
    "for i in range(len(syllables_list)):\n",
    "    #for each syllable bigrams\n",
    "    for j in range(len(syllables_list[i])-1):\n",
    "        curr_tup=tuple([syllables_list[i][j],syllables_list[i][j+1]])\n",
    "        #if the curr syllable bigrams is in dict\n",
    "        if curr_tup in syllable_bigrams.keys():\n",
    "            #increament count\n",
    "            syllable_bigrams[curr_tup]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            syllable_bigrams[curr_tup]=1\n",
    "#sorting syllable bigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(syllable_bigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#writing top 100 syllable bigrams into text file\n",
    "with io.open('syllable_bigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i][0])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][1])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c69fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store syllable trigrams and their counts\n",
    "syllable_trigrams=dict()\n",
    "#for each word\n",
    "for i in range(len(syllables_list)):\n",
    "    #for each syllable trigrams\n",
    "    for j in range(len(syllables_list[i])-2):\n",
    "        curr_tup=tuple([syllables_list[i][j],syllables_list[i][j+1],syllables_list[i][j+2]])\n",
    "        #if the curr syllable trigrams is in dict\n",
    "        if curr_tup in syllable_trigrams.keys():\n",
    "            #increament count\n",
    "            syllable_trigrams[curr_tup]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            syllable_trigrams[curr_tup]=1\n",
    "#sorting syllable trigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(syllable_trigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#writing top 100 syllable trigrams into text file\n",
    "with io.open('syllable_trigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i][0])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][1])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][2])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eefd2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store syllable quadrigrams and their counts\n",
    "syllable_quadrigrams=dict()\n",
    "#for each word\n",
    "for i in range(len(syllables_list)):\n",
    "    #for each syllable quadrigrams\n",
    "    for j in range(len(syllables_list[i])-3):\n",
    "        curr_tup=tuple([syllables_list[i][j],syllables_list[i][j+1],syllables_list[i][j+2],syllables_list[i][j+3]])\n",
    "        #if the curr syllable quadrigrams is in dict\n",
    "        if curr_tup in syllable_quadrigrams.keys():\n",
    "            #increament count\n",
    "            syllable_quadrigrams[curr_tup]+=1\n",
    "        #else\n",
    "        else:\n",
    "            #initialize count\n",
    "            syllable_quadrigrams[curr_tup]=1\n",
    "#sorting syllable quadrigrams based on counts\n",
    "sorted_list=[k for k, v in sorted(syllable_quadrigrams.items(), key=lambda item: item[1],reverse=True)]\n",
    "#writing top 100 syllable quadrigrams into text file\n",
    "with io.open('syllable_quadrigrams.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for i in range(min(len(sorted_list),100)):\n",
    "        f.write(sorted_list[i][0])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][1])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][2])\n",
    "        f.write(' ')\n",
    "        f.write(sorted_list[i][3])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f5c47",
   "metadata": {},
   "source": [
    "## 3.d:Testing if frequency of characters, syllables and words follow Zipfian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ff92901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot zipf distrubution vs character,syllable or word distributions\n",
    "#level is either character or word or syllable\n",
    "#data is the corresponding zipf dict of that level\n",
    "def plot_zipf(level,data):\n",
    "    #getting current level frequencies\n",
    "    s = list(data.values())\n",
    "    #converting to array\n",
    "    s = np.array(s)\n",
    "    #getting sum\n",
    "    su=sum(s)\n",
    "    #normalizing\n",
    "    s=s/max(s)\n",
    "    #getting random samples from zipf distribution\n",
    "    x = random.zipf(a=1.001, size=su)\n",
    "    #sorting samples\n",
    "    x.sort()\n",
    "    #getting value counts\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    #getting only top rank items from counts, so that no of items in counts and s are same\n",
    "    counts=counts[:len(s)]\n",
    "    #normalizing\n",
    "    counts=counts/max(counts)\n",
    "    #plotting distributions\n",
    "    plt.plot(counts[:min(500,len(counts))],label=level)\n",
    "    plt.plot(s[:min(500,len(counts))],label='zipf')\n",
    "    plt.xlabel('rank')\n",
    "    plt.ylabel('normalized frequency')\n",
    "    plt.title(level+'  distribution  vs  ' +'zipf distribution')\n",
    "    plt.legend()\n",
    "    #saving in image\n",
    "    plt.savefig(level+'_zipf.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e7d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ea4c11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting distributions for all three levels and saving them in images\n",
    "plot_zipf('characters',char_zipf)\n",
    "plot_zipf('words',word_zipf)\n",
    "plot_zipf('syllables',syllable_zipf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305fc98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
